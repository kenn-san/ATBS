<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Confidence-based Event-centric Online Video Question Answering on a Newly Constructed ATBS Dataset.">
  <meta name="keywords" content="Online Video Question Answering, Video Understanding, Open-ended VideoQA, VideoQA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Confidence-based Event-centric Online Video Question Answering on a Newly Constructed ATBS Dataset</title>

  <!-- Mathjax CDN-->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!--link rel="icon" href=""-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!--
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Confidence-based Event-centric Online Video Question Answering on a Newly Constructed ATBS Dataset.</h1>
          <div class="is-size-5 publication-authors">
            <!--Weikai Kong$^{\star}$$^{\ddagger}$, Shuhong Ye$^{\star}$$^{\ddagger}$,  Chenglin Yao$^{\star}$, Jianfeng Ren-->
            <span class="author-block">
              <a href="https://github.com/WeikaiKong">Weikai Kong</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/kenn-san">Shuhong Ye</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.researchgate.net/profile/Chenglin_Yao2">Chenglin Yao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://research.nottingham.edu.cn/en/persons/jianfeng-ren">Jianfeng Ren</a><sup>1,2</sup>,
            </span>
          </div>
          
          <!--⋆School of Computer Science, University of Nottingham Ningbo China
          †Nottingham Ningbo China Beacons of Excellence Research and Innovation Institute,
          University of Nottingham Ningbo China, China-->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Nottingham Ningbo China, China,</span>
            <span class="author-block"><sup>2</sup>Nottingham Ningbo China Beacons of Excellence Research and Innovation Institute,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              
              <!-- PDF Link. -->
             
              <span class="link-block">
                <a href="#TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper(Pending)</span>
                </a>
              </span>
              <!--
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              -->

              <!-- Video Link. -->
              <!--
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->

              <!-- Code Link. -->
              <span class="link-block">
                <a href="#TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(Under Construction)</span>
                  </a>
              </span>

              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1xO6KVUj2QLjZweqiXqIMRmuSjVjHuYOy?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>ATBS Dataset</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
-->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">          
          <p>
            Deep neural networks facilitate video question answering (VideoQA), but the real-world applications on video streams
            such as CCTV and live cast place higher demands on the solver. To address the challenges of VideoQA on long videos of
            unknown length, we define a new set of problems called Online Open-ended Video Question Answering (O<sup>2</sup>VQA). It
            requires an online state-updating mechanism for the solver to decide if the collected information is sufficient to
            conclude an answer. We then propose a Confidence-based Event-centric Online Video Question Answering (CEO-VQA) model to
            solve this problem. Furthermore, a dataset called Answer Target in Background Stream (ATBS) is constructed to evaluate
            this newly developed online VideoQA application. Compared to the baseline VideoQA method that watches the whole video,
            the experimental results show that the proposed method achieves a significant performance gain.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
  </div>
</section>

<!-- Figure -->
<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <!--/ Architecture. -->
        <div class="section-title has-text-centered">
          <h2 class="title is-3 is-centered">Illustration of the Online Open-ended Video Question Answering task</h2>
        </div>
        <div class="column"></div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="static/images/Online Video QA Illustration.png">
            </div>
          </div>
        </div>
        <p>
          Illustration of Online Open-ended Video Question Answering (O<sup>2</sup>VQA) task. 
          For each frame, the solver derives the confidence score for each of the feasible candidate answers and decides if the evidence is sufficient to give a confident answer.
        </p>
    </div>
  </div>
</section>

<!-- Algorithm -->
<section class="section">
  <div class="container is-max-desktop">

    <div class="section-title has-text-centered">
      <h2 class="title is-3 is-centered">CEO-VQA Algorithm</h2>
    </div>
    <div class="column"></div>

    <div class="columns is-centered">

      <!-- Cross domain. -->
      <div class="column">
        <div class="content">
          <p class="is-centered has-text-centered">
            The proposed CEO-VQA consists of two main modules:
          </p>
          <p>
            1) <b>Confidence-based Target Event Locator.</b> 
            Given an online video stream and a question, the confidence to answer $c$ is
            derived by using a <b>VideoTextEncoder</b> to evaluate the attentional information
            between the text features extracted from the question and the visual features extracted from the video stream. The
            Confidence-based Target Event Locator then filters out irrelevant events and locates the target event $\mathcal{T}$.
            To reduce the time complexity, we bi-directionally traverse the video in a Fibonacci way.
          </p>
          <p>
            2) <b>Event Question Answering.</b>
            After locating the target event, a <b>VideoEncoder</b> is utilized to extract the visual
            features from the video key frames, and a <b>QuestionEncoder</b> is utilized to
            extract the linguistic features. The visual and linguistic features are then concatenated and fed into a <b>MultiModal
            Encoder</b> to perform cross-modal learning. Finally, a reliable answer is generated by the answer decoder.<br>
          </p>
          <div class="publication-img is-centered has-text-centered">
            <img id="style_transfer" height="75%" width="75%" src="static/images/Pseudocode.png" >
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<!-- Related Links -->
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            <a href="https://github.com/LisaAnne/TemporalLanguageRelease">DiDeMo</a> dataset used as our background video source.
          </p>
          <p>
            <a href="https://www.robots.ox.ac.uk/~maxbain/frozen-in-time/data/">MSRVTT-QA</a> used as our target video source. 
            *(We use the link provided by <a href="https://github.com/m-bain/frozen-in-time/blob/main/README.md">Frozen️ in Time</a>)
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{kong2023confidence,
      author    = {Kong, Weikai and Ye, Shuhong and Chenglin, Yao and Jianfeng, Ren},
      title     = {Confidence-based Event-centric Online Video Question Answering on a Newly Constructed ATBS Dataset},
      booktitle = {{IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP} 2023},
      publisher = {{IEEE}},
      year      = {2023},
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="#TODO">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="#TODO" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies project page</a>. If you want to reuse their source code, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
